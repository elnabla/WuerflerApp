{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "import json\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tk\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f53618",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_DIMS = [256, 256]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8778c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90654fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_points(points, new_dim, old_dim):\n",
    "    new_points = []\n",
    "    for point in points:\n",
    "        new = [float(point[0]) * new_dim[1] / old_dim[1], float(point[1]) * new_dim[0] / old_dim[0] ]\n",
    "        new_points.append(new)\n",
    "    return np.array(new_points).astype('int32')\n",
    " \n",
    "def get_file_mask(i):\n",
    "    im_dir = \"./images/imgs_2022/\"\n",
    "    ann_path = f\"./images/annotated/im{i}.json\" # dirty\n",
    "    with open(ann_path) as file:\n",
    "        data = json.load(file)\n",
    "    points = data['shapes'][0]['points']\n",
    "    im_path = im_dir + data['imagePath'].split('/')[-1]\n",
    "    image = cv2.imread(im_path)\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    BIG_DIMS = image.shape\n",
    "\n",
    "    points = resize_points(points, IM_DIMS, BIG_DIMS)\n",
    "\n",
    "\n",
    "    points = np.array(points).astype('int32')\n",
    "\n",
    "    \n",
    "    small_image = cv2.resize(image, [IM_DIMS[1], IM_DIMS[0]])\n",
    "    bg = np.zeros(small_image.shape[:2])\n",
    "    bg = cv2.fillPoly(bg, [points], 1)\n",
    "    bg = bg.astype('int8')\n",
    "    return small_image, bg\n",
    "\n",
    "def write_dataset():\n",
    "    impath = \"./images/training/images/\"\n",
    "    lblpath = \"./images/training/labels/\"\n",
    "    for i in range(1, 28):\n",
    "        image, label = get_file_mask(i)\n",
    "        cv2.imwrite(impath + f\"{i}.png\", image)\n",
    "        cv2.imwrite(lblpath + f\"{i}.png\", label)\n",
    "        \n",
    "def get_XY_data():\n",
    "    X_data = []\n",
    "    Y_data = []\n",
    "    for i in range(1,28):\n",
    "        image, label = get_file_mask(i)\n",
    "        X_data.append(image)\n",
    "        Y_data.append(label)\n",
    "    #X_data = np.expand_dims(X_data, axis=3)\n",
    "    Y_data = np.expand_dims(Y_data, axis=3)\n",
    "    return np.array(X_data), np.array(Y_data)\n",
    "        \n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb44117",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = get_file_mask(1)\n",
    "print(mask.shape)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd70f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_dataset()\n",
    "X_data, Y_data = get_XY_data()\n",
    "X_data = X_data.astype(\"float\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_data[5], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(Y_data[5], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime data augmentation\n",
    "def get_train_test_augmented(X_data, Y_data, validation_split=0.1, batch_size=32, seed=42):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_data,\n",
    "                                                        Y_data,\n",
    "                                                        train_size=1-validation_split,\n",
    "                                                        test_size=validation_split,\n",
    "                                                        random_state=seed)\n",
    "    \n",
    "    # Image data generator distortion options\n",
    "    data_gen_args = dict(rotation_range=5.,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         shear_range=0.05,\n",
    "                         zoom_range=0.05,\n",
    "                         horizontal_flip=False,\n",
    "                         vertical_flip=False,\n",
    "                         fill_mode='nearest')  #use 'constant'??\n",
    "\n",
    "\n",
    "    # Train data, provide the same seed and keyword arguments to the fit and flow methods\n",
    "    X_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    Y_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    X_datagen.fit(X_train, augment=True, seed=seed)\n",
    "    Y_datagen.fit(Y_train, augment=True, seed=seed)\n",
    "    X_train_augmented = X_datagen.flow(X_train, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "    Y_train_augmented = Y_datagen.flow(Y_train, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "     \n",
    "    \n",
    "    # Test data, no data augmentation, but we create a generator anyway\n",
    "    X_datagen_val = ImageDataGenerator()\n",
    "    Y_datagen_val = ImageDataGenerator()\n",
    "    X_datagen_val.fit(X_test, augment=True, seed=seed)\n",
    "    Y_datagen_val.fit(Y_test, augment=True, seed=seed)\n",
    "    X_test_augmented = X_datagen_val.flow(X_test, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "    Y_test_augmented = Y_datagen_val.flow(Y_test, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "    \n",
    "    \n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = zip(X_train_augmented, Y_train_augmented)\n",
    "    test_generator = zip(X_test_augmented, Y_test_augmented)\n",
    "    \n",
    "    return train_generator, test_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d60700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers\n",
    " \n",
    "def double_conv_block(x, n_filters):\n",
    "    # Conv2D then ReLU activation\n",
    "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "    #x = layers.BatchNormalization()(x)\n",
    "    # Conv2D then ReLU activation\n",
    "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
    "    #x = layers.BatchNormalization()(x)    \n",
    "    return x\n",
    "\n",
    "def downsample_block(x, n_filters):\n",
    "    f = double_conv_block(x, n_filters)\n",
    "    p = layers.MaxPool2D(2)(f)\n",
    "    p = layers.Dropout(0.3)(p)\n",
    "    return f, p\n",
    "\n",
    "def upsample_block(x, conv_features, n_filters):\n",
    "    # upsample\n",
    "    x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "    # concatenate\n",
    "    x = layers.concatenate([x, conv_features])\n",
    "    # dropout\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    # Conv2D twice with ReLU activation\n",
    "    x = double_conv_block(x, n_filters)\n",
    "\n",
    "    return x\n",
    "\n",
    "def get_model():\n",
    "    inputs = tf.keras.Input(shape=(256, 256, 3))\n",
    "    # encoder: contracting path - downsample\n",
    "    # 1 - downsample\n",
    "    f1, p1 = downsample_block(inputs, 32)\n",
    "    # 2 - downsample\n",
    "    f2, p2 = downsample_block(p1, 64)\n",
    "    # 3 - downsample\n",
    "    f3, p3 = downsample_block(p2, 128)\n",
    "    # 4 - downsample\n",
    "    f4, p4 = downsample_block(p3, 256)\n",
    "    # 5 - bottleneck\n",
    "    bottleneck = double_conv_block(p4, 512)\n",
    "    # decoder: expanding path - upsample\n",
    "    # 6 - upsample\n",
    "    u6 = upsample_block(bottleneck, f4, 256)\n",
    "    # 7 - upsample\n",
    "    u7 = upsample_block(u6, f3, 128)\n",
    "    # 8 - upsample\n",
    "    u8 = upsample_block(u7, f2, 64)\n",
    "    # 9 - upsample\n",
    "    u9 = upsample_block(u8, f1, 32)\n",
    "    # outputs\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
    "    # unet model with Keras Functional API\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "    return unet_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Build model\n",
    "model = get_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec921502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.optimizers import SGD\n",
    "#opt = SGD(learning_rate=0.01)\n",
    "\n",
    "# Configure the model for training.\n",
    "# We use the \"sparse\" version of categorical_crossentropy\n",
    "# because our target data is integers.\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e71a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, doing validation at the end of each epoch.\n",
    "train_gen, _ = get_train_test_augmented(X_data=X_data,Y_data=Y_data)\n",
    "\n",
    "X_data_aug = []\n",
    "Y_data_aug= []\n",
    "\n",
    "for i in range(100): \n",
    "    X_tmp, Y_tmp = next(train_gen)\n",
    "    X_data_aug.append(X_tmp)\n",
    "    Y_data_aug.append(Y_tmp)\n",
    "X_data_aug = np.vstack(X_data_aug)\n",
    "Y_data_aug = np.vstack(Y_data_aug)\n",
    "\n",
    "X_data_aug.shape, Y_data_aug.shape\n",
    "\n",
    "\n",
    "np.savez(\"data_augmented.npz\", X_data=X_data_aug, Y_data=Y_data_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data_aug,\n",
    "                                                        Y_data_aug,\n",
    "                                                        train_size=1-0.1,\n",
    "                                                        test_size=0.1,\n",
    "                                                        random_state=42)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape\n",
    "del(X_data_aug)\n",
    "del(Y_data_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e16b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"mymodel_augment.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "epochs = 1\n",
    "model.fit(\n",
    "    X_train, Y_train,\n",
    "    batch_size=32,\n",
    "    epochs=epochs,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=None,\n",
    "    validation_batch_size=None,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f98fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01396d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.min(), preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(preds[0], cmap='gray')\n",
    "preds.min(), preds.max()\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "bce(Y_train[0:1], preds).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be92693",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Y_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e345db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731bac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "im, mask = next(train_gen)\n",
    "plt.imshow(im[0])\n",
    "plt.show()\n",
    "plt.imshow(mask[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a94b17",
   "metadata": {},
   "source": [
    "Epoch 1/10\n",
    "68/68 [==============================] - 2195s 32s/step - loss: 0.6877 - accuracy: 0.4563 - val_loss: 0.6782 - val_accuracy: 0.4595\n",
    "Epoch 2/10\n",
    "68/68 [==============================] - 2207s 32s/step - loss: 0.7230 - accuracy: 0.4563 - val_loss: 0.6655 - val_accuracy: 0.4595\n",
    "Epoch 3/10\n",
    "68/68 [==============================] - 2205s 32s/step - loss: 0.6856 - accuracy: 0.4563 - val_loss: 0.6368 - val_accuracy: 0.4595\n",
    "Epoch 4/10\n",
    "68/68 [==============================] - 2204s 32s/step - loss: 0.6088 - accuracy: 0.4563 - val_loss: 0.4325 - val_accuracy: 0.4595\n",
    "Epoch 5/10\n",
    "68/68 [==============================] - 2214s 33s/step - loss: 0.4587 - accuracy: 0.4563 - val_loss: 0.3462 - val_accuracy: 0.4595\n",
    "Epoch 6/10\n",
    "68/68 [==============================] - 2213s 33s/step - loss: 0.3527 - accuracy: 0.4563 - val_loss: 0.3645 - val_accuracy: 0.4595\n",
    "Epoch 7/10\n",
    "68/68 [==============================] - 2208s 32s/step - loss: 0.3332 - accuracy: 0.4563 - val_loss: 0.3218 - val_accuracy: 0.4595\n",
    "Epoch 8/10\n",
    "68/68 [==============================] - 2228s 33s/step - loss: 0.3366 - accuracy: 0.4563 - val_loss: 0.2713 - val_accuracy: 0.4595\n",
    "Epoch 9/10\n",
    "68/68 [==============================] - 2213s 33s/step - loss: 0.2824 - accuracy: 0.4563 - val_loss: 0.1981 - val_accuracy: 0.4595\n",
    "Epoch 10/10\n",
    "68/68 [==============================] - 2210s 33s/step - loss: 0.2114 - accuracy: 0.4563 - val_loss: 0.1495 - val_accuracy: 0.4595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43189b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"test.png\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b7c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
