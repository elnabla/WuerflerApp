{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba3217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "import json\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tk\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f53618",
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_DIMS = [256, 256]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8778c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90654fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_points(points, new_dim, old_dim):\n",
    "    new_points = []\n",
    "    for point in points:\n",
    "        new = [float(point[0]) * new_dim[1] / old_dim[1], float(point[1]) * new_dim[0] / old_dim[0] ]\n",
    "        new_points.append(new)\n",
    "    return np.array(new_points).astype('int32')\n",
    " \n",
    "def get_file_mask(i):\n",
    "    im_dir = \"./images/imgs_2022/\"\n",
    "    ann_path = f\"./images/annotated/im{i}.json\" # dirty\n",
    "    with open(ann_path) as file:\n",
    "        data = json.load(file)\n",
    "    points = data['shapes'][0]['points']\n",
    "    im_path = im_dir + data['imagePath'].split('/')[-1]\n",
    "    image = cv2.imread(im_path)\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    BIG_DIMS = image.shape\n",
    "\n",
    "    points = resize_points(points, IM_DIMS, BIG_DIMS)\n",
    "\n",
    "\n",
    "    points = np.array(points).astype('int32')\n",
    "\n",
    "    \n",
    "    small_image = cv2.resize(image, [IM_DIMS[1], IM_DIMS[0]])\n",
    "    bg = np.zeros(small_image.shape[:2])\n",
    "    bg = cv2.fillPoly(bg, [points], 1)\n",
    "    bg = bg.astype('int8')\n",
    "    return small_image, bg\n",
    "\n",
    "def write_dataset():\n",
    "    impath = \"./images/training/images/\"\n",
    "    lblpath = \"./images/training/labels/\"\n",
    "    for i in range(1, 28):\n",
    "        image, label = get_file_mask(i)\n",
    "        cv2.imwrite(impath + f\"{i}.png\", image)\n",
    "        cv2.imwrite(lblpath + f\"{i}.png\", label)\n",
    "        \n",
    "def get_XY_data():\n",
    "    X_data = []\n",
    "    Y_data = []\n",
    "    for i in range(1,28):\n",
    "        image, label = get_file_mask(i)\n",
    "        X_data.append(image)\n",
    "        Y_data.append(label)\n",
    "    #X_data = np.expand_dims(X_data, axis=3)\n",
    "    Y_data = np.expand_dims(Y_data, axis=3)\n",
    "    return np.array(X_data), np.array(Y_data)\n",
    "        \n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb44117",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = get_file_mask(1)\n",
    "print(mask.shape)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd70f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_dataset()\n",
    "X_data, Y_data = get_XY_data()\n",
    "X_data = X_data.astype(\"float\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_data[5], cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(Y_data[5], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime data augmentation\n",
    "def get_train_test_augmented(X_data, Y_data, validation_split=0.1, batch_size=32, seed=42):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_data,\n",
    "                                                        Y_data,\n",
    "                                                        train_size=1-validation_split,\n",
    "                                                        test_size=validation_split,\n",
    "                                                        random_state=seed)\n",
    "    \n",
    "    # Image data generator distortion options\n",
    "    data_gen_args = dict(rotation_range=5.,\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         shear_range=0.05,\n",
    "                         zoom_range=0.05,\n",
    "                         horizontal_flip=False,\n",
    "                         vertical_flip=False,\n",
    "                         fill_mode='nearest')  #use 'constant'??\n",
    "\n",
    "\n",
    "    # Train data, provide the same seed and keyword arguments to the fit and flow methods\n",
    "    X_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    Y_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    X_datagen.fit(X_train, augment=True, seed=seed)\n",
    "    Y_datagen.fit(Y_train, augment=True, seed=seed)\n",
    "    X_train_augmented = X_datagen.flow(X_train, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "    Y_train_augmented = Y_datagen.flow(Y_train, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "     \n",
    "    \n",
    "    # Test data, no data augmentation, but we create a generator anyway\n",
    "    X_datagen_val = ImageDataGenerator()\n",
    "    Y_datagen_val = ImageDataGenerator()\n",
    "    X_datagen_val.fit(X_test, augment=True, seed=seed)\n",
    "    Y_datagen_val.fit(Y_test, augment=True, seed=seed)\n",
    "    X_test_augmented = X_datagen_val.flow(X_test, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "    Y_test_augmented = Y_datagen_val.flow(Y_test, batch_size=batch_size, shuffle=True, seed=seed)\n",
    "    \n",
    "    \n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = zip(X_train_augmented, Y_train_augmented)\n",
    "    test_generator = zip(X_test_augmented, Y_test_augmented)\n",
    "    \n",
    "    return train_generator, test_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d60700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "\"\"\"\n",
    "A Keras implementation of TernausNet16: \n",
    "https://arxiv.org/abs/1801.05746\n",
    "https://github.com/ternaus/TernausNet\n",
    "The architecture is very similar to the original U-net paper:\n",
    "https://arxiv.org/abs/1505.04597\n",
    "The key differences are:\n",
    "- A VGG16 architecture is used for encoder, pretrained on ImageNet\n",
    "- No batchnorm used\n",
    "- No dropout used\n",
    "- Shortcut concatenations are mismatched on number of filters meaning that \n",
    "  a larger number of filters is used in decoder.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def decoder_block_ternausV2(inputs, mid_channels, out_channels):\n",
    "    \"\"\"\n",
    "    Decoder block as proposed for TernausNet16 here: \n",
    "    https://arxiv.org/abs/1801.05746\n",
    "    See DecoderBlockV2 here:\n",
    "    https://github.com/ternaus/TernausNet/blob/master/unet_models.py\n",
    "    - Concatenate u-net shortcut to input pre-upsample\n",
    "    - Bilinear upsample input to double Height and Width dimensions\n",
    "    - Note: The original ternausNet implementation includes option for \n",
    "      deconvolution instead of bilinear upsampling. Omitted here because I \n",
    "      couldn't find a meaningful performance comparison\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_kwargs = dict(\n",
    "        activation='relu',\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal',\n",
    "        data_format='channels_last'  # (batch, height, width, channels)\n",
    "    )\n",
    "\n",
    "    x = UpSampling2D(size=(2, 2))(inputs) # interpolation='bilinear' doesn't work?\n",
    "    x = Conv2D(mid_channels, 3, **conv_kwargs)(x)\n",
    "    x = Conv2D(out_channels, 3, **conv_kwargs)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# INTENDED API\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def ternausNet16(input_size=(256, 256, 3), output_channels=1):\n",
    "    \"\"\"\n",
    "    A Keras implementation of TernausNet16: \n",
    "    https://arxiv.org/abs/1801.05746\n",
    "    https://github.com/ternaus/TernausNet\n",
    "    \"\"\"\n",
    "\n",
    "    # input \n",
    "    # convert 1 channel grayscale to 3 channels if needed\n",
    "    inputs = Input(input_size)\n",
    "    if input_size[-1] < 3:\n",
    "        x = Conv2D(3, 1)(inputs)                         # add channels\n",
    "        input_shape = (input_size[0], input_size[0], 3)  # update input size\n",
    "    else:\n",
    "        x = inputs\n",
    "        input_shape = input_size\n",
    "    \n",
    "    # Load pretrained VGG, conv layers include relu activation\n",
    "    encoder = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "       \n",
    "    # (None, 256, 256, 3)\n",
    "    e1 = encoder.get_layer(name='block1_conv1')(x)\n",
    "    e1 = encoder.get_layer(name='block1_conv2')(e1)\n",
    "    # (None, 256, 256, 64)\n",
    "    e2 = MaxPooling2D(pool_size=(2, 2))(e1)\n",
    "    e2 = encoder.get_layer(name='block2_conv1')(e2)\n",
    "    e2 = encoder.get_layer(name='block2_conv2')(e2)\n",
    "    # (None, 128, 128, 128)\n",
    "    e3 = MaxPooling2D(pool_size=(2, 2))(e2)\n",
    "    e3 = encoder.get_layer(name='block3_conv1')(e3)\n",
    "    e3 = encoder.get_layer(name='block3_conv2')(e3)\n",
    "    e3 = encoder.get_layer(name='block3_conv3')(e3)\n",
    "    # (None, 64, 64, 256)\n",
    "    e4 = MaxPooling2D(pool_size=(2, 2))(e3)\n",
    "    e4 = encoder.get_layer(name='block4_conv1')(e4)\n",
    "    e4 = encoder.get_layer(name='block4_conv2')(e4)\n",
    "    e4 = encoder.get_layer(name='block4_conv3')(e4)\n",
    "    # (None, 32, 32, 512)\n",
    "    e5 = MaxPooling2D(pool_size=(2, 2))(e4)\n",
    "    e5 = encoder.get_layer(name='block5_conv1')(e5)\n",
    "    e5 = encoder.get_layer(name='block5_conv2')(e5)\n",
    "    e5 = encoder.get_layer(name='block5_conv3')(e5)\n",
    "    # (None, 16, 16, 512)\n",
    "    center = MaxPooling2D(pool_size=(2, 2))(e5)\n",
    "    # (None, 8, 8, 512)\n",
    "    center = decoder_block_ternausV2(center, 512, 256)\n",
    "    # (None, 16, 16, 256)\n",
    "    d5 = concatenate([e5, center], axis=3)\n",
    "    d5 = decoder_block_ternausV2(d5, 512, 256)\n",
    "    # (None, 32, 32, 256)\n",
    "    d4 = concatenate([e4, d5], axis=3)\n",
    "    d4 = decoder_block_ternausV2(d4, 512, 128)\n",
    "    # (None, 64, 64, 128)\n",
    "    d3 = concatenate([e3, d4], axis=3)\n",
    "    d3 = decoder_block_ternausV2(d3, 256, 64)\n",
    "    # (None, 128, 128, 64)\n",
    "    d2 = concatenate([e2, d3], axis=3)\n",
    "    d2 = decoder_block_ternausV2(d2, 128, 64)\n",
    "    # (None, 256, 256, 64)\n",
    "    # Note: no decoder block used at end\n",
    "    d1 = concatenate([e1, d2], axis=3)\n",
    "    d1 = Conv2D(32, 3, padding='same', kernel_initializer='he_normal')(d1)\n",
    "    d1 = ReLU()(d1)\n",
    "    # (None, 256, 256, 32)\n",
    "\n",
    "    # Output\n",
    "    if output_channels > 1:\n",
    "        # untested\n",
    "        op = tf.nn.log_softmax_v2(d1, axis=3)\n",
    "    else:\n",
    "        op = Conv2D(output_channels, 1)(d1)\n",
    "        op = Activation('sigmoid')(op)  # note: ternaus excludes\n",
    "\n",
    "    # Build\n",
    "    model = Model(inputs=[inputs], outputs=[op])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec921502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.optimizers import SGD\n",
    "#opt = SGD(learning_rate=0.01)\n",
    "\n",
    "# Configure the model for training.\n",
    "# We use the \"sparse\" version of categorical_crossentropy\n",
    "# because our target data is integers.\n",
    "model = ternausNet16()\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e71a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, doing validation at the end of each epoch.\n",
    "train_gen, _ = get_train_test_augmented(X_data=X_data,Y_data=Y_data)\n",
    "\n",
    "X_data_aug = []\n",
    "Y_data_aug= []\n",
    "\n",
    "for i in range(1): \n",
    "    X_tmp, Y_tmp = next(train_gen)\n",
    "    X_data_aug.append(X_tmp)\n",
    "    Y_data_aug.append(Y_tmp)\n",
    "X_data_aug = np.vstack(X_data_aug)\n",
    "Y_data_aug = np.vstack(Y_data_aug)\n",
    "\n",
    "X_data_aug.shape, Y_data_aug.shape\n",
    "\n",
    "\n",
    "np.savez(\"data_augmented.npz\", X_data=X_data_aug, Y_data=Y_data_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data_aug,\n",
    "                                                        Y_data_aug,\n",
    "                                                        train_size=1-0.1,\n",
    "                                                        test_size=0.1,\n",
    "                                                        random_state=42)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape\n",
    "del(X_data_aug)\n",
    "del(Y_data_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e16b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"mymodel_ternaus.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "epochs = 1\n",
    "model.fit(\n",
    "    X_train, Y_train,\n",
    "    batch_size=2,\n",
    "    epochs=epochs,\n",
    "    verbose=\"auto\",\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=5,\n",
    "    validation_steps=2,\n",
    "    validation_batch_size=2,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tf.keras.models.load_model(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f98fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(np.array([X_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01396d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.min(), preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab6951",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(preds[0], cmap='gray')\n",
    "preds[0].min(), preds[0].max()\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "bce(Y_train[0:1], preds).numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be92693",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Y_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e345db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731bac64",
   "metadata": {},
   "outputs": [],
   "source": [
    "im, mask = next(train_gen)\n",
    "plt.imshow(im[0])\n",
    "plt.show()\n",
    "plt.imshow(mask[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e837f3",
   "metadata": {},
   "source": [
    "Epoch 1/10\n",
    "68/68 [==============================] - 2195s 32s/step - loss: 0.6877 - accuracy: 0.4563 - val_loss: 0.6782 - val_accuracy: 0.4595\n",
    "Epoch 2/10\n",
    "68/68 [==============================] - 2207s 32s/step - loss: 0.7230 - accuracy: 0.4563 - val_loss: 0.6655 - val_accuracy: 0.4595\n",
    "Epoch 3/10\n",
    "68/68 [==============================] - 2205s 32s/step - loss: 0.6856 - accuracy: 0.4563 - val_loss: 0.6368 - val_accuracy: 0.4595\n",
    "Epoch 4/10\n",
    "68/68 [==============================] - 2204s 32s/step - loss: 0.6088 - accuracy: 0.4563 - val_loss: 0.4325 - val_accuracy: 0.4595\n",
    "Epoch 5/10\n",
    "68/68 [==============================] - 2214s 33s/step - loss: 0.4587 - accuracy: 0.4563 - val_loss: 0.3462 - val_accuracy: 0.4595\n",
    "Epoch 6/10\n",
    "68/68 [==============================] - 2213s 33s/step - loss: 0.3527 - accuracy: 0.4563 - val_loss: 0.3645 - val_accuracy: 0.4595\n",
    "Epoch 7/10\n",
    "68/68 [==============================] - 2208s 32s/step - loss: 0.3332 - accuracy: 0.4563 - val_loss: 0.3218 - val_accuracy: 0.4595\n",
    "Epoch 8/10\n",
    "68/68 [==============================] - 2228s 33s/step - loss: 0.3366 - accuracy: 0.4563 - val_loss: 0.2713 - val_accuracy: 0.4595\n",
    "Epoch 9/10\n",
    "68/68 [==============================] - 2213s 33s/step - loss: 0.2824 - accuracy: 0.4563 - val_loss: 0.1981 - val_accuracy: 0.4595\n",
    "Epoch 10/10\n",
    "68/68 [==============================] - 2210s 33s/step - loss: 0.2114 - accuracy: 0.4563 - val_loss: 0.1495 - val_accuracy: 0.4595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43189b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "2213/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebdee42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
